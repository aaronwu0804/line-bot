#!/usr/bin/env python3
"""
æ•´åˆç¯„ä¾‹ - å±•ç¤ºå¦‚ä½•åœ¨ app.py ä¸­æ•´åˆèŠ±ç”ŸåŠ©æ‰‹çš„æ–°åŠŸèƒ½

é€™å€‹æª”æ¡ˆå±•ç¤ºäº†å¦‚ä½•ä¿®æ”¹ç¾æœ‰çš„ app.py ä¾†ä½¿ç”¨æ–°çš„æ™ºèƒ½åŠŸèƒ½
"""

# ========================
# æ­¥é©Ÿ 1: åŒ¯å…¥æ–°æ¨¡çµ„
# ========================

import asyncio
from src.peanut_assistant import peanut_assistant
from src.intent_classifier import intent_classifier

# ========================
# æ­¥é©Ÿ 2: ä¿®æ”¹è¨Šæ¯è™•ç†å‡½æ•¸
# ========================

# åŸæœ‰çš„ handle_message å‡½æ•¸

# @handler.add(MessageEvent, message=TextMessageContent)
# def handle_message(event):
#     """è™•ç†æ–‡å­—è¨Šæ¯"""
#     user_message = event.message.text
#     user_id = event.source.user_id
#     reply_token = event.reply_token
    
#     # æª¢æŸ¥æ˜¯å¦ç‚º AI è«‹æ±‚
#     if is_ai_request(user_message):
#         # åŸæœ‰çš„è™•ç†é‚è¼¯...
#         pass

# ========================
# æ–°çš„è¨Šæ¯è™•ç†å‡½æ•¸ï¼ˆæ•´åˆèŠ±ç”ŸåŠ©æ‰‹ï¼‰
# ========================

@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    """è™•ç†æ–‡å­—è¨Šæ¯ï¼ˆæ•´åˆèŠ±ç”ŸåŠ©æ‰‹ç‰ˆæœ¬ï¼‰"""
    user_message = event.message.text
    user_id = event.source.user_id
    reply_token = event.reply_token
    
    logger.info(f"æ”¶åˆ°è¨Šæ¯: user_id={user_id}, message={user_message}")
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºã€Œä½¿ç”¨èªªæ˜ã€è«‹æ±‚
    if user_message.strip() in ['ä½¿ç”¨èªªæ˜', 'èªªæ˜', 'help', 'å¹«åŠ©', 'åŠŸèƒ½']:
        usage_guide = peanut_assistant.get_usage_guide()
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=usage_guide)]
                )
            )
        return
    
    # æª¢æŸ¥æ˜¯å¦ç‚º AI è«‹æ±‚
    if is_ai_request(user_message):
        try:
            # å…ˆå›è¦†ã€Œæ­£åœ¨è™•ç†ã€è¨Šæ¯
            with ApiClient(configuration) as api_client:
                line_bot_api = MessagingApi(api_client)
                line_bot_api.reply_message(
                    ReplyMessageRequest(
                        reply_token=reply_token,
                        messages=[TextMessage(text="ğŸ¤” è®“æˆ‘æƒ³æƒ³...")]
                    )
                )
            
            # ä½¿ç”¨èŠ±ç”ŸåŠ©æ‰‹è™•ç†è¨Šæ¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                peanut_assistant.process_message(user_id, user_message)
            )
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ AI å›æ‡‰
            if result.get("needs_ai_response"):
                # ä½¿ç”¨åŸæœ‰çš„ AI å›æ‡‰ç³»çµ±ï¼Œä½†åŠ å…¥è¨˜æ†¶ä¸Šä¸‹æ–‡
                context = result.get("context", "")
                query = extract_query(user_message)
                
                # å–å¾—å°è©±æ­·å²
                conversation_history = conversation_histories.get(user_id, [])
                
                # å¦‚æœæœ‰è¨˜æ†¶ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°ç³»çµ±æç¤ºä¸­
                if context:
                    system_prompt = f"""ä½ æ˜¯èŠ±ç”Ÿ AI å°å¹«æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç”¨æˆ¶çš„ç›¸é—œè¨˜æ†¶å’Œè³‡è¨Šï¼š

{context}

è«‹æ ¹æ“šé€™äº›è³‡è¨Šï¼Œä»¥åŠç”¨æˆ¶çš„å•é¡Œï¼Œæä¾›å€‹äººåŒ–çš„å›æ‡‰ã€‚
å›ç­”è¦å‹å–„ã€æœ‰å¹«åŠ©ï¼Œä¸¦å±•ç¾å‡ºä½ è¨˜å¾—ç”¨æˆ¶åˆ†äº«çš„è³‡è¨Šã€‚"""
                    
                    # ä½¿ç”¨å¸¶ä¸Šä¸‹æ–‡çš„ AI å›æ‡‰
                    ai_response = get_ai_response_with_context(
                        query, 
                        conversation_history,
                        system_prompt
                    )
                else:
                    # ä½¿ç”¨åŸæœ‰çš„ AI å›æ‡‰
                    ai_response = get_ai_response(query, conversation_history)
                
                # æ¨é€ AI å›æ‡‰
                push_message_to_user(user_id, ai_response)
                
                # æ›´æ–°å°è©±æ­·å²
                update_conversation_history(user_id, query, ai_response)
                
            else:
                # ç›´æ¥æ¨é€èŠ±ç”ŸåŠ©æ‰‹çš„å›æ‡‰
                response = result.get("response", "")
                if response:
                    push_message_to_user(user_id, response)
            
        except Exception as e:
            logger.error(f"è™•ç†è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            push_message_to_user(user_id, "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è¨Šæ¯æ™‚ç™¼ç”Ÿäº†éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
    
    else:
        # é AI è«‹æ±‚ï¼Œå›è¦†ä½¿ç”¨èªªæ˜
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=get_help_message())]
                )
            )

# ========================
# æ­¥é©Ÿ 3: æ–°å¢å¸¶ä¸Šä¸‹æ–‡çš„ AI å›æ‡‰å‡½æ•¸
# ========================

def get_ai_response_with_context(query, conversation_history=None, system_prompt=None):
    """
    ç²å– AI å›æ‡‰ï¼ˆå¸¶è‡ªè¨‚ç³»çµ±æç¤ºï¼‰
    
    Args:
        query: ç”¨æˆ¶æŸ¥è©¢
        conversation_history: å°è©±æ­·å²
        system_prompt: è‡ªè¨‚ç³»çµ±æç¤ºï¼ˆåŒ…å«è¨˜æ†¶ä¸Šä¸‹æ–‡ï¼‰
    
    Returns:
        str: AI å›æ‡‰
    """
    try:
        # ä½¿ç”¨è‡ªè¨‚ç³»çµ±æç¤ºæˆ–é è¨­æç¤º
        if not system_prompt:
            system_prompt = """ä½ æ˜¯ä¸€å€‹å‹å–„ã€æœ‰å¹«åŠ©çš„ AI åŠ©ç†ã€ŒèŠ±ç”Ÿã€ã€‚
è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œï¼Œèªæ°£è¦æº«æš–ã€è‡ªç„¶ï¼Œå°±åƒå’Œæœ‹å‹èŠå¤©ä¸€æ¨£ã€‚
å¦‚æœä¸ç¢ºå®šç­”æ¡ˆï¼Œè«‹èª å¯¦èªªæ˜ï¼Œä¸è¦ç·¨é€ è³‡è¨Šã€‚"""
        
        # å»ºç«‹å°è©±å…§å®¹
        messages = [{"role": "system", "content": system_prompt}]
        
        # åŠ å…¥å°è©±æ­·å²
        if conversation_history:
            for item in conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘ 5 è¼ªå°è©±
                messages.append({"role": "user", "content": item.get("query", "")})
                messages.append({"role": "assistant", "content": item.get("response", "")})
        
        # åŠ å…¥ç•¶å‰æŸ¥è©¢
        messages.append({"role": "user", "content": query})
        
        # å‘¼å« Gemini API
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # è½‰æ›è¨Šæ¯æ ¼å¼
        gemini_messages = []
        for msg in messages:
            if msg["role"] == "system":
                # Gemini å°‡ system prompt åˆä½µåˆ°ç¬¬ä¸€å€‹ user message
                continue
            elif msg["role"] == "user":
                gemini_messages.append({
                    "role": "user",
                    "parts": [msg["content"]]
                })
            elif msg["role"] == "assistant":
                gemini_messages.append({
                    "role": "model",
                    "parts": [msg["content"]]
                })
        
        # å¦‚æœæœ‰ system promptï¼ŒåŠ åˆ°ç¬¬ä¸€å€‹ user message
        if system_prompt and gemini_messages:
            gemini_messages[0]["parts"][0] = f"{system_prompt}\n\n{gemini_messages[0]['parts'][0]}"
        
        # ç”Ÿæˆå›æ‡‰
        chat = model.start_chat(history=gemini_messages[:-1] if len(gemini_messages) > 1 else [])
        response = chat.send_message(gemini_messages[-1]["parts"][0])
        
        return response.text.strip()
    
    except Exception as e:
        logger.error(f"AI å›æ‡‰ç”Ÿæˆå¤±æ•—: {e}")
        return "æŠ±æ­‰ï¼ŒAI å›æ‡‰ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# ========================
# æ­¥é©Ÿ 4: æ›´æ–°ä½¿ç”¨èªªæ˜è¨Šæ¯
# ========================

def get_help_message():
    """ç”¢ç”Ÿä½¿ç”¨èªªæ˜è¨Šæ¯ï¼ˆæ›´æ–°ç‰ˆï¼‰"""
    return peanut_assistant.get_usage_guide()

# ========================
# ä½¿ç”¨ç¯„ä¾‹
# ========================

"""
ç¯„ä¾‹å°è©±æµç¨‹ï¼š

ç”¨æˆ¶: "èŠ±ç”Ÿï¼Œæˆ‘æ˜å¤©è¦é–‹æœƒ"
â†“
1. is_ai_request() åˆ¤æ–·ç‚º AI è«‹æ±‚ âœ“
2. peanut_assistant.process_message() è™•ç†
3. intent_classifier åˆ†é¡ç‚º "todo-create"
4. todo_manager æ–°å¢å¾…è¾¦äº‹é …
5. å›æ‡‰: "âœ… å·²æ–°å¢å¾…è¾¦äº‹é …ï¼šæˆ‘æ˜å¤©è¦é–‹æœƒ (æˆªæ­¢ï¼š2026-02-25)"

---

ç”¨æˆ¶: "ä»Šå¤©å­¸åˆ°äº† Python çš„ asyncio"
â†“
1. is_ai_request() åˆ¤æ–·ç‚º AI è«‹æ±‚ âœ“
2. peanut_assistant.process_message() è™•ç†
3. intent_classifier åˆ†é¡ç‚º "save_content-knowledge"
4. content_manager å„²å­˜å…§å®¹
5. memory_manager å„²å­˜åˆ°é•·æœŸè¨˜æ†¶
6. å›æ‡‰: "âœ… å·²å„²å­˜åˆ° ğŸ“š çŸ¥è­˜\\n\\nå…§å®¹ï¼šä»Šå¤©å­¸åˆ°äº† Python çš„ asyncio"

---

ç”¨æˆ¶: "æ¨è–¦ä¸€äº›å¥½æ›¸çµ¦æˆ‘"
â†“
1. is_ai_request() åˆ¤æ–·ç‚º AI è«‹æ±‚ âœ“
2. peanut_assistant.process_message() è™•ç†
3. intent_classifier åˆ†é¡ç‚º "query-recommendation"
4. memory_manager æœå°‹ç›¸é—œè¨˜æ†¶
5. æ‰¾åˆ°ç”¨æˆ¶ä¹‹å‰åˆ†äº«çš„é–±è®€åå¥½
6. ä½¿ç”¨å¸¶ä¸Šä¸‹æ–‡çš„ AI å›æ‡‰
7. å›æ‡‰: "æ ¹æ“šä½ ä¹‹å‰æåˆ°çš„å–œå¥½...æˆ‘æ¨è–¦ä»¥ä¸‹æ›¸ç±..."

---

ç”¨æˆ¶: "æŸ¥çœ‹å¾…è¾¦"
â†“
1. is_ai_request() åˆ¤æ–·ç‚º AI è«‹æ±‚ âœ“
2. peanut_assistant.process_message() è™•ç†
3. intent_classifier åˆ†é¡ç‚º "todo-query"
4. todo_manager æŸ¥è©¢å¾…è¾¦äº‹é …
5. æ ¼å¼åŒ–é¡¯ç¤º
6. å›æ‡‰: "ğŸ“‹ æ‚¨çš„å¾…è¾¦äº‹é …ï¼š\\nâ³ å¾…å®Œæˆï¼š\\n1. æˆ‘æ˜å¤©è¦é–‹æœƒ (æˆªæ­¢ï¼šæ˜å¤©)"
"""

# ========================
# æ³¨æ„äº‹é …
# ========================

"""
1. è¨˜å¾—åœ¨ app.py é–‹é ­åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„ï¼š
   from src.peanut_assistant import peanut_assistant
   import asyncio

2. ç¢ºä¿å·²å®‰è£æ‰€æœ‰ä¾è³´ï¼š
   pip install -r requirements.txt

3. è¨­å®šå¿…è¦çš„ç’°å¢ƒè®Šæ•¸ï¼š
   LINE_CHANNEL_ACCESS_TOKEN
   LINE_CHANNEL_SECRET
   GEMINI_API_KEY
   MEM0_API_KEYï¼ˆå¯é¸ï¼‰

4. æ¸¬è©¦åŠŸèƒ½ï¼š
   python test_peanut_features.py

5. æœ¬åœ°æ¸¬è©¦ï¼š
   python app.py

6. éƒ¨ç½²åˆ° Render æ™‚æœƒè‡ªå‹•ä½¿ç”¨é€™äº›æ–°åŠŸèƒ½
"""
